:toc:

= Terraform Workshop

* https://www.terraform.io[terraform.io]: "Terraform is an open-source infrastructure as code software tool that provides a consistent CLI workflow to manage hundreds of cloud services. Terraform codifies cloud APIs into declarative configuration files."
* written in "HashiCorp Configuration Language" (HCL) in file with .tf extension
* support to cloud vendor via https://registry.terraform.io/browse/providers[providers], which have to be downloaded from the https://registry.terraform.io[registry] when used
* example: https://registry.terraform.io/providers/hashicorp/aws/latest/docs[Using AWS Provider]
* benefit of Terraform: syntax for each provider is the same, hence not the specifics of a provider have to be learned, they are abstracted away by Terraform scripts that look the same for each provider.

== Creating First Resources

Resource syntax:

[source,hcl-terraform]
----
resource "<provider>_<resource_type>" "name" {
  config options
}
----

* _<provider>_ will be "aws" if AWS is to be targeted
* _<resource_type>_ can also be found in the https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ami[documentation]

For example:

.01-create-ec2/main.tf
[source,hcl-terraform]
----
# Create a VPC
resource "aws_vpc" "example" {
  cidr_block = "10.0.0.0/16"
}
----

Or:

.01-create-ec2/main.tf
[source,hcl-terraform]
----
# Create an EC2
resource "aws_instance" "my-instance" {
  # Ubuntu Server 20.04 LTS
  ami = "ami-0d527b8c289b4af7f"
  instance_type = "t2.micro"
}
----

**AMI-IDs are region-specific! When copy-pasting an ID from the web console, make sure to select the right region.**

In the directory where the above file is located, Terraform has to be initiated to download all the necessary providers into the folder _.terraform_:

[source,terminal]
----
$ terraform init

Initializing the backend...

Initializing provider plugins...
- Finding hashicorp/aws versions matching "~> 3.0"...
- Installing hashicorp/aws v3.74.3...
- Installed hashicorp/aws v3.74.3 (signed by HashiCorp)

Terraform has created a lock file .terraform.lock.hcl to record the provider
selections it made above. Include this file in your version control repository
so that Terraform can guarantee to make the same selections by default when
you run "terraform init" in the future.

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
----

The command _terraform init_ is idempotent, it can be run multiple times in the same directory.

**The automatically created file .terraform.lock.hcl should be added to version control!**

**The automatically created file terraform.tfstate is needed to manage the state and must not be deleted. Also, in includes sensitive information and should not be put in version control!**

Validate configuration with

[source,terminal]
----
$ terraform validate
Success! The configuration is valid.
----

List of all resources to be created with

[source,terminal]
----
terraform plan

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following
symbols:
  + create

Terraform will perform the following actions:

  # aws_instance.my-instance will be created
  + resource "aws_instance" "my-instance" {
      + ami                                  = "ami-0d527b8c289b4af7f"
      + arn                                  = (known after apply)
      + associate_public_ip_address          = (known after apply)
      + availability_zone                    = (known after apply)
      + cpu_core_count                       = (known after apply)
      + cpu_threads_per_core                 = (known after apply)
      + disable_api_termination              = (known after apply)
      + ebs_optimized                        = (known after apply)
      + get_password_data                    = false
      + host_id                              = (known after apply)
      + id                                   = (known after apply)
      + instance_initiated_shutdown_behavior = (known after apply)
      + instance_state                       = (known after apply)
      + instance_type                        = "t2.micro"
      + ipv6_address_count                   = (known after apply)
      + ipv6_addresses                       = (known after apply)
      + key_name                             = (known after apply)
      + monitoring                           = (known after apply)
      + outpost_arn                          = (known after apply)
      + password_data                        = (known after apply)
      + placement_group                      = (known after apply)
      + placement_partition_number           = (known after apply)
      + primary_network_interface_id         = (known after apply)
      + private_dns                          = (known after apply)
      + private_ip                           = (known after apply)
      + public_dns                           = (known after apply)
      + public_ip                            = (known after apply)
      + secondary_private_ips                = (known after apply)
      + security_groups                      = (known after apply)
      + source_dest_check                    = true
      + subnet_id                            = (known after apply)
      + tags_all                             = (known after apply)
      + tenancy                              = (known after apply)
      + user_data                            = (known after apply)
      + user_data_base64                     = (known after apply)
      + vpc_security_group_ids               = (known after apply)

      + capacity_reservation_specification {
          + capacity_reservation_preference = (known after apply)

          + capacity_reservation_target {
              + capacity_reservation_id = (known after apply)
            }
        }

      + ebs_block_device {
          + delete_on_termination = (known after apply)
          + device_name           = (known after apply)
          + encrypted             = (known after apply)
          + iops                  = (known after apply)
          + kms_key_id            = (known after apply)
          + snapshot_id           = (known after apply)
          + tags                  = (known after apply)
          + throughput            = (known after apply)
          + volume_id             = (known after apply)
          + volume_size           = (known after apply)
          + volume_type           = (known after apply)
        }

      + enclave_options {
          + enabled = (known after apply)
        }

      + ephemeral_block_device {
          + device_name  = (known after apply)
          + no_device    = (known after apply)
          + virtual_name = (known after apply)
        }

      + metadata_options {
          + http_endpoint               = (known after apply)
          + http_put_response_hop_limit = (known after apply)
          + http_tokens                 = (known after apply)
          + instance_metadata_tags      = (known after apply)
        }

      + network_interface {
          + delete_on_termination = (known after apply)
          + device_index          = (known after apply)
          + network_interface_id  = (known after apply)
        }

      + root_block_device {
          + delete_on_termination = (known after apply)
          + device_name           = (known after apply)
          + encrypted             = (known after apply)
          + iops                  = (known after apply)
          + kms_key_id            = (known after apply)
          + tags                  = (known after apply)
          + throughput            = (known after apply)
          + volume_id             = (known after apply)
          + volume_size           = (known after apply)
          + volume_type           = (known after apply)
        }
    }

Plan: 1 to add, 0 to change, 0 to destroy.

─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

Note: You didn't use the -out option to save this plan, so Terraform can't guarantee to take exactly these actions if you run "terraform
apply" now.
----

Create resources specified in current folder with:

[source,terminal]
----
$ terraform apply
----

Multiple executions of _terraform apply_ will not create multiple resources because of the names of the created resources and the declarative approach.

After modifications, run _terraform plan_ and after that _terraform apply_.

== Destroying Resources

To destroy all resources defined in the files in the current directory and created by those resources, run:

[source,terminal]
----
$ terraform destroy
----

Also, resources existing in AWS but not defined in Terraform will be deleted when executing _Terraform apply_.

== Referencing Resources

References to other resources are done with the <resource_type>.<resource_name>.id like in this example:

.02-referencing-resources/main.tf
[source,hcl-terraform]
----
# Create a VPC and subnet
resource "aws_vpc" "vpc-1" {
  cidr_block = "10.0.0.0/16"
  tags = {
    Name = "production "
  }
}

resource "aws_subnet" "subnet-1" {
  vpc_id = aws_vpc.vpc-1.id
  cidr_block = "10.0.1.0/24"
  tags = {
    Name = "prod-subnet"
  }
}
----

Using the _Name_-tag will allow easy identification of the created resource in the AWS web console because the name of resources will be shown there, if the tag is _Name_ (with upper-case!).

Resources don't need to be declared in a specific order, Terraform figures out what to create first by itself. It creates a dependency graph from all the references that can be printed with:

[source,terminal]
----
$ terraform graph
----

Output of _terraform graph_ is written in DOT and can be converted to images using tools like https://dreampuf.github.io/GraphvizOnline/[Graphviz Online].


== User Data

When starting an EC2 instance, user data can be defined to run some script after creation of the instance.

.03-practice-project/main.tf
[source,hcl-terraform]
----
resource "aws_instance" "web-server-instance" {
  # Ubuntu Server 20.04 LTS
  ami = "ami-04505e74c0741db8d"
  instance_type = "t2.micro"
  availability_zone = "us-east-1a"
  key_name = "main-keypair"

  network_interface {
    device_index = 0
    network_interface_id = aws_network_interface.web-server-nic.id
  }

  user_data = <<-EOF
    #!/bin/bash
    sudo apt update -y
    sudo apt install apache2 -y
    sudo systemctl start apache2
    sudo bash -c 'echo your very first web server > /var/www/html/index.html'
    EOF
  tags = {
    Name = "web-server"
  }
}
----

== Output Variables

Within Terraform script, *output* can be defined like this (values from '_terraform state show aws_some_resource_'):

[source,hcl-terraform]
----
# Print public IP of server after creation
output "server_public_ip" {
  value = aws_eip.aws_eip.public_ip
}
----

_output_ can be every Terraform expression.

As a best practice, outputs should reside in a file *outputs.tf*.

After _terraform apply_, *all* outputs can be printed again using

[source,terminal]
----
$ terraform output
----

*Certain* outputs can be printed using

[source,terminal]
----
$ terraform output server_public_ip
----

Output variables may contain a configuration with the following parameters:

* description
* sensitive (true, if the output should not be printed at the end of _apply_)

Example for showing public IP address of server:

[source,hcl-terraform]
----
output "public_ip" {
  value = aws_instance.example.public_ip
  description = "The public IP address of the web server"
}
----

== Useful Commands and Settings

To automatically *confirm* changes:

[source,terminal]
----
$ terraform apply --auto-approve
----

*Show current state*:

[source,hcl-terraform]
----
$ terraform show
----

*List* all resources:

[source,terminal]
----
$ terraform state list
----

*Show details* about one of the resources:

[source,terminal]
----
$ terraform state show aws_some_resource
----

To *refresh* all states and run the outputs again (great for printing the IPs mentioned before):

[source,terminal]
----
$ terraform refresh
----

*Targeting* single resources instead of changing all the resources in a script:

[source,terminal]
----
$ terraform destroy -target aws_some_resource
$ terraform apply -target aws_some_resource
----

== Input Variables

To follow the DRY principle, code can be extracted into variables that have three parts:

* description
* default (optional)
* type (for example string, number, bool, list, map, set, object, tuple, any)

For example, extract the CIDR block from the following code:

[source,hcl-terraform]
----
resource "aws_subnet" "subnet-1" {
  vpc_id = aws_vpc.prod-vpc.id
  cidr_block = "10.0.1.0/24"
  availability_zone = "us-east-1a"
  tags = {
    Name = "prod-subnet"
  }
}
----

The following code will ask for a value for _subnet_prefix_ when performing _terraform apply_:

[source,hcl-terraform]
----
variable "subnet_prefix" {
  description = "cidr block for subnet"
  type = string
}

resource "aws_subnet" "subnet-1" {
  vpc_id = aws_vpc.prod-vpc.id
  cidr_block = var.subnet_prefix
  availability_zone = "us-east-1a"
  tags = {
    Name = "prod-subnet"
  }
}
----

It will also ask for a value when destroying the resource, which doesn't matter so any value can be entered or none at all.

When creating the resources, the value could be assigned via a _default_ field in the definition of the variable.

Alternatively, it can be defined as a command line argument:

[source,terminal]
----
$ terraform apply -var "subnet_prefix=10.0.100.0/24"
----

However, best solution to define variables is via a separate file called *_terraform.tfvars_* in the same directory as the _.tf_ file:

.terraform.tfvars
[source,hcl-terraform]
----
subnet_prefix = "10.0.200.0/24"
----

When creating multiple variable files, the default name _terraform.tfvars_ cannot be used. References to variable files can be assigned with:

[source,terminal]
----
$ terraform apply --var-file example.tfvars
----

Example with combined types:

[source,hcl-terraform]
----
variable "list_numeric_example" {
  description = "An example of a numeric list in Terraform"
  type = list(number)
  default = [1, 2, 3]
}
----

Example with combined, structural types:

[source,hcl-terraform]
----
variable "object_example" {
  description = "An example of a structural type in Terraform"
  type = object({
    name = string
    age = number
    tags = list(string)
    enabled = bool
  })
  default = {
    name = "value1"
    age = 42
    tags = ["a", "b", "c"]
    enabled = true
  }
}
----

Using *interpolation*, a variable can also be used in the user data block:

[source,hcl-terraform]
----
user_data = <<-EOF
  #!/bin/bash
  echo "Hello, World" > index.html
  nohup busybox httpd -f -p ${var.server_port} &
  EOF
----

== Sources
* https://www.youtube.com/watch?v=SLB_c_ayRMo["Terraform Course - Automate your AWS cloud infrastructure"], YouTube, 2:20:57
* https://learn.hashicorp.com[HashiCorp Learn], tutorials from HashiCorp
* https://www.terraformupandrunning.com[Terraform: Up and Running, Second Edition] by Yevgeniy Brikman (O’Reilly). Copyright 2019 Yevgeniy Brikman, 978-1-492-04690-5.














